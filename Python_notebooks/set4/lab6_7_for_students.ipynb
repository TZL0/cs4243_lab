{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b0ca6cb",
   "metadata": {},
   "source": [
    "# Lab Weeks 6 and 7\n",
    "### This is considered for week 6 and 7 labs, \n",
    "### For Students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d447c7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing modules \n",
    "import cv2     # open cv 2 package\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e234ce6",
   "metadata": {},
   "source": [
    "\n",
    "### part 1:  \n",
    "#### 30 minutesfor CW1 trouble shooting, \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72148ae",
   "metadata": {},
   "source": [
    "### Part 2: Texture Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4e3184",
   "metadata": {},
   "source": [
    "### 2-1: LBP: Local Binary Patterns\n",
    "#### A. Standard LBP\n",
    "1. Develop a standard LBP function\n",
    "2. Try it on \n",
    "a. IMG_0054_1024bw.bmp \n",
    "b. djzam_nat_defect_002_2g_8.bmp \n",
    "c. diag_texture.bmp \n",
    "d. hor_texture.jpg \n",
    "3. If the image is color, convert it to graylevel\n",
    "4. Draw the histogram of the LBP, see the differences, discuss it\n",
    "5. In pparticular, compare the histogram of the LBPs of a and b, and c and d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a716e799",
   "metadata": {},
   "source": [
    "#### B. Try to develop a radial P=16, R=3 LBP function\n",
    "#### See Slide 23, c \n",
    "Then try it on \n",
    "- cat_bw.bmp\n",
    "- djzam_nat_defect_002_2g_8.bmp\n",
    "Plot the resulting histogram. How many bins has it got? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfcec39",
   "metadata": {},
   "source": [
    "### 2-2: GLCM matrices \n",
    "#### Develop a routine to compute the GLCM matrix of an image. Input parameters could be the gray-level image, \n",
    "#### number of possible gray-levels of that image, and the distance and direction between paired pixels\n",
    "#### You may test your routine on the small size matrices available in slides\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3499876b",
   "metadata": {},
   "source": [
    "1. Try your GLCM routine on a few textures, e.g.\n",
    "- hor_texture.jpg\n",
    "2. Dont forget to convert the image to GL if it's necessary\n",
    "3- Go for d=1 , and Theta= 0 \n",
    "4- Apply the F1 and F2 on your GLCM matrices and see the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8677827e",
   "metadata": {},
   "source": [
    "## 2-3: GLCM-based Texture Analysis\n",
    "1. For images below, where GL=256 for all, \n",
    "- hor_texture.jpg \n",
    "- high_spat_freq.bmp\n",
    "- IMG_8636q.jpg \n",
    "2. Convert them the GL if it's necessary \n",
    "3. Apply a Gaussian lowpass filter on IMG_8636q.jpg next\n",
    "4. Compute 4 GLCM matrices for distance=d=[1,5] , theta= [0,90] for each texture\n",
    "5. Compute F1 and F2 for each GLCM matrix. \n",
    "6. This way, you will have a 2-feature feature vector for each GLCM matrix, \n",
    "- or a 8-feature feature vector to represent your texture\n",
    "7. Compare GLCMs' [F1, F2] feature vectors with each other and discuss the results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53401403",
   "metadata": {},
   "source": [
    "### you may use function below to compute F1 and F2, for your texture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1244179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract 2 features from the glcm matrix. \n",
    "# input is the glcm matrix \n",
    "# output is maximum and energy, F1 andd F2 \n",
    "# definitions in the course slides\n",
    "#\n",
    "def glcm_feat( g11 ):\n",
    "    mxx = np.max(g11)\n",
    "    enrg = np.sum(np.multiply(g11,g11))\n",
    "    \n",
    "    return  mxx , enrg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e2780c",
   "metadata": {},
   "source": [
    "### 2-3: Laws Filters: A bank of small size filters to extract texture features\n",
    "#### \n",
    "1. Use instructions below to creat a 9-filter 3x3 Laws filter bank \n",
    "2. Use images below, apply all Laws filters on them, compute the filter response\n",
    "3. Filter responses will configure a 9-featured feature vector\n",
    "- Images: \n",
    "- IMG_0054_1024bw.bmp\n",
    "- 20230515_110806.jpg \n",
    "- djzam_nat_defect_002_2g_8.bmp \n",
    "- 20230324_105524gl.jpg \n",
    "4. Discuss the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7414e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0625 0.125  0.0625]\n",
      " [0.125  0.25   0.125 ]\n",
      " [0.0625 0.125  0.0625]]\n",
      "[[-0.25  0.    0.25]\n",
      " [-0.5   0.    0.5 ]\n",
      " [-0.25  0.    0.25]]\n",
      "[[-0.25  0.5  -0.25]\n",
      " [-0.5   1.   -0.5 ]\n",
      " [-0.25  0.5  -0.25]]\n",
      "[[-0.25 -0.5  -0.25]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.25  0.5   0.25]]\n",
      "[[ 1  0 -1]\n",
      " [ 0  0  0]\n",
      " [-1  0  1]]\n",
      "[[ 1 -2  1]\n",
      " [ 0  0  0]\n",
      " [-1  2 -1]]\n",
      "[[-0.25 -0.5  -0.25]\n",
      " [ 0.5   1.    0.5 ]\n",
      " [-0.25 -0.5  -0.25]]\n",
      "[[ 1  0 -1]\n",
      " [-2  0  2]\n",
      " [ 1  0 -1]]\n",
      "[[ 1 -2  1]\n",
      " [-2  4 -2]\n",
      " [ 1 -2  1]]\n"
     ]
    }
   ],
   "source": [
    "# Law's filters\n",
    "L = np.array([1,2,1]) / 4\n",
    "# or: L = np.array([1,2,1])\n",
    "E = np.array([-1,0,1])\n",
    "S = np.array([-1,2,-1])\n",
    "llist = [L, E, S]\n",
    "\n",
    "laws = []\n",
    "for xs in llist:\n",
    "    for ys in llist:\n",
    "        xs= np.reshape(xs,(3,1))\n",
    "        ys = np.reshape(ys,(1,3))\n",
    "        L3L3 = np.matmul(xs,ys)  \n",
    "        print(L3L3)\n",
    "        laws.append(L3L3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cb486f",
   "metadata": {},
   "source": [
    "\n",
    "#### now in laws we have got a list of 9 filters, 3x3 each\n",
    "### \n",
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0763cc4",
   "metadata": {},
   "source": [
    "### 2-4: Gabor Filters: MSMD Approaches\n",
    "#### \n",
    "1. Use images below and Gabor function in the next cell, \n",
    "2. Try different parameters of the Gabor filter and see the results\n",
    "- Images: \n",
    "- IMG_0054_1024bw.bmp\n",
    "- 20230515_110806.jpg \n",
    "- djzam_nat_defect_002_2g_8.bmp \n",
    "- 20230324_105524gl.jpg \n",
    "4. Discuss the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecefdd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gabor filter routine, to generate a Gabor filter with given parameters, output is a Gabor filter\n",
    "# you can use it later if you like\n",
    "#\n",
    "\n",
    "def gabor(sigma, theta, Lambda, psi, gamma):\n",
    "    sigma_x = sigma\n",
    "    sigma_y = float(sigma) / gamma\n",
    "\n",
    "    # Bounding box\n",
    "    nstds = 3  # Number of standard deviation sigma\n",
    "    xmax = max(abs(nstds * sigma_x * np.cos(theta)), abs(nstds * sigma_y * np.sin(theta)))\n",
    "    xmax = np.ceil(max(1, xmax))\n",
    "    ymax = max(abs(nstds * sigma_x * np.sin(theta)), abs(nstds * sigma_y * np.cos(theta)))\n",
    "    ymax = np.ceil(max(1, ymax))\n",
    "    xmin = -xmax\n",
    "    ymin = -ymax\n",
    "    (y, x) = np.meshgrid(np.arange(ymin, ymax + 1), np.arange(xmin, xmax + 1))\n",
    "\n",
    "    # Rotation\n",
    "    x_theta = x * np.cos(theta) + y * np.sin(theta)\n",
    "    y_theta = -x * np.sin(theta) + y * np.cos(theta)\n",
    "\n",
    "    gb = np.exp(-.5 * (x_theta ** 2 / sigma_x ** 2 + y_theta ** 2 / sigma_y ** 2)) * np.cos(2 * np.pi / Lambda * x_theta + psi)\n",
    "    return gb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4274f77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n\\n# cv2.getGaborKernel(ksize, sigma, theta, lambda, gamma, psi, ktype)\\n# 2d Gabor filter for image processing, is a 2d sine wave modulated by a Gaussian envelop\\n# \\n# -- ksize - size of gabor filter (n, n), usually it is small, e.g. 7x7 to 30x30, size of the filter\\n# matrix\\n# -- sigma - standard deviation of the gaussian function, filter bandwidth, bandwidth of that Gaussian envelop\\n# -- theta - orientation of the normal to the parallel stripes, we can rotate the filter, \\n# direction of the 2d sine wave\\n# -- lambda - wavelength of the sunusoidal factor, wavelength = 1/ frequency of the filter sine wave\\n# -- gamma - spatial aspect ratio, \\n# -- psi - phase offset, usually 0 , phase of that sine wave\\n# -- ktype - type and range of values that each pixel in the gabor kernel can hold,\\n#either 32 bit or 64 bit, float \\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "''' \n",
    "\n",
    "# cv2.getGaborKernel(ksize, sigma, theta, lambda, gamma, psi, ktype)\n",
    "# 2d Gabor filter for image processing, is a 2d sine wave modulated by a Gaussian envelop\n",
    "# \n",
    "# -- ksize - size of gabor filter (n, n), usually it is small, e.g. 7x7 to 30x30, size of the filter\n",
    "# matrix\n",
    "# -- sigma - standard deviation of the gaussian function, filter bandwidth, bandwidth of that Gaussian envelop\n",
    "# -- theta - orientation of the normal to the parallel stripes, we can rotate the filter, \n",
    "# direction of the 2d sine wave\n",
    "# -- lambda - wavelength of the sunusoidal factor, wavelength = 1/ frequency of the filter sine wave\n",
    "# -- gamma - spatial aspect ratio, \n",
    "# -- psi - phase offset, usually 0 , phase of that sine wave\n",
    "# -- ktype - type and range of values that each pixel in the gabor kernel can hold,\n",
    "#either 32 bit or 64 bit, float \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6539e39c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'im_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m g_kernel90 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mgetGaborKernel((\u001b[38;5;241m21\u001b[39m, \u001b[38;5;241m21\u001b[39m), \u001b[38;5;241m8.0\u001b[39m, np\u001b[38;5;241m.\u001b[39mpi\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m10.0\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0\u001b[39m, ktype\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mCV_32F)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# image in gray level and convolution for 2d filtering\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[43mim_name\u001b[49m,\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      7\u001b[0m filtered_img90 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mfilter2D(img, cv2\u001b[38;5;241m.\u001b[39mCV_8UC3, g_kernel90)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# showing the input and filtered images\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'im_name' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# building the filter kernel\n",
    "g_kernel90 = cv2.getGaborKernel((21, 21), 8.0, np.pi/2, 10.0, 0.5, 0, ktype=cv2.CV_32F)\n",
    "\n",
    "# image in gray level and convolution for 2d filtering\n",
    "img = cv2.imread(im_name,0)\n",
    " \n",
    "filtered_img90 = cv2.filter2D(img, cv2.CV_8UC3, g_kernel90)\n",
    "\n",
    "# showing the input and filtered images\n",
    "cv2.imshow('image', img)\n",
    "cv2.imshow('filtered image, theta=90', filtered_img90)\n",
    "\n",
    "# making the filter larger just to show that\n",
    "h, w = g_kernel90.shape[:2]\n",
    "g_kernel2 = cv2.resize(g_kernel90, (10*w, 10*h), interpolation=cv2.INTER_CUBIC)\n",
    "cv2.imshow('gabor kernel, theta=90 (resized)', g_kernel2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
