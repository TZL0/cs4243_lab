{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "img: The input grayscale image.\n",
    "GL: Number of gray levels.\n",
    "d: The distance between pixel pairs.\n",
    "t: The angle (in degrees) specifying the direction of pixel pairs.\n",
    "\"\"\"\n",
    "def am_glcm_faster( img , GL , d , t):\n",
    "    ccmm = np.zeros([GL, GL])\n",
    "    if t==0:\n",
    "        im_target = img[:,d:]\n",
    "        im_value = img[:,:-d]\n",
    "        '''\n",
    "        1 2 3 4 5 6 7 8 9 10  original\n",
    "        1 2 3 4 5 6 7 8 9     target\n",
    "          2 3 4 5 6 7 8 9 10  value\n",
    "        '''\n",
    "    elif t==45:\n",
    "        im_target = img[d:,d:]\n",
    "        im_value = img[:-d, :-d]\n",
    "    elif t==90:\n",
    "        im_target = img[d:,:]\n",
    "        im_value = img[:-d, :]\n",
    "    elif t==135:\n",
    "        im_target = img[:-d, :-d]\n",
    "        im_value = img[d:,d:]\n",
    "    else:\n",
    "        raise NotImplementedError('t options: 0, 45, 90, 135 only')\n",
    "    assert im_target.shape==im_value.shape\n",
    "    ref_gls = np.unique(im_value)\n",
    "    # print(ref_gls)\n",
    "    for ref in ref_gls:\n",
    "        #ref: 80\n",
    "        target_values = im_target[im_value == ref]\n",
    "        #target_values: [ 98,  89,  99, 100]\n",
    "        target_gls = np.unique(target_values)\n",
    "        #[ 89,  98,  99, 100]\n",
    "        for target in target_gls:\n",
    "\n",
    "               ccmm[ref, target] = (target_values==target).sum()\n",
    "    return ccmm\n",
    "\n",
    "\n",
    "# function to compute the image power. input could be graylevel or color.\n",
    "#\n",
    "def am_power(a):\n",
    "    dim1 = a.shape\n",
    "\n",
    "    if len(dim1)==2:\n",
    "        sz = dim1[0] * dim1[1]\n",
    "    elif len(dim1)==3:\n",
    "        sz = dim1[0] * dim1[1] * dim1[2]\n",
    "    pa = np.sum( a ** 2.0) / sz\n",
    "\n",
    "    return pa\n",
    "\n",
    "def am_entropy(nimg , N=256):\n",
    "    M = nimg.shape\n",
    "    ssz = M[0] * M[1]\n",
    "    hist,bins = np.histogram(nimg.flatten(),N,[0,N])\n",
    "    hist = hist / ssz\n",
    "    ent = -np.sum( hist * np.log2(hist+0.000001))\n",
    "    return ent\n",
    "\n",
    "glcm_energy = lambda gl : np.sum(np.multiply(gl,gl))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "test_img1 = cv2.imread('/Users/tianze/cs4243_lab/CS4243_2023_images_small/collage1.bmp', 0)\n",
    "test_img2 = cv2.imread('/Users/tianze/cs4243_lab/CS4243_2023_images_small/20230324_105524gl.jpg', 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# Separate a 512*512 path of each from <0,0> to <512,512>, we call them a5, b5\n",
    "a5 = test_img1[0:512, 0:512]\n",
    "b5 = test_img2[0:512, 0:512]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['glcma5390', 23644310.0], ['glcma530', 123233206.0], ['glcmb530', 132581438.0], ['glcmb5390', 150995342.0]]\n"
     ]
    }
   ],
   "source": [
    "glcma530 = am_glcm_faster(a5, 256, 3, 0)\n",
    "glcma5390 = am_glcm_faster(a5, 256, 3, 90)\n",
    "glcmb530 = am_glcm_faster(b5, 256, 3, 0)\n",
    "glcmb5390 = am_glcm_faster(b5, 256, 3, 90)\n",
    "\n",
    "ls = [['glcma530',glcma530], ['glcma5390', glcma5390], ['glcmb530', glcmb530], ['glcmb5390', glcmb5390]]\n",
    "print(sorted(map(lambda x: [x[0], glcm_energy(x[1])], ls), key=lambda x: x[1]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "c = cv2.imread('//Users/tianze/cs4243_lab/CS4243_2023_images_small/IMG_0054.JPG', 0)\n",
    "d = cv2.imread('//Users/tianze/cs4243_lab/CS4243_2023_images_small/6ae-007.jpg', 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image power c=  15875.908085340141\n",
      "power of c 0 th filter response= 15632.804892407947\n",
      "power of c 1 th filter response= 367.35752368398494\n",
      "power of c 2 th filter response= 81.87042335867245\n",
      "power of c 3 th filter response= 519.2561169735623\n",
      "power of c 4 th filter response= 320.66703837861354\n",
      "power of c 5 th filter response= 124.87064970009018\n",
      "power of c 6 th filter response= 94.2810190940469\n",
      "power of c 7 th filter response= 132.59986965274604\n",
      "power of c 8 th filter response= 124.51946238505309\n",
      "original image power d=  7340.401925308194\n",
      "power of d 0 th filter response= 7294.189411711385\n",
      "power of d 1 th filter response= 45.623743654822334\n",
      "power of d 2 th filter response= 16.272286983321248\n",
      "power of d 3 th filter response= 102.31650108774474\n",
      "power of d 4 th filter response= 69.06252356780276\n",
      "power of d 5 th filter response= 38.73454133430022\n",
      "power of d 6 th filter response= 40.261400471356055\n",
      "power of d 7 th filter response= 74.31934372733865\n",
      "power of d 8 th filter response= 56.88379441624365\n"
     ]
    }
   ],
   "source": [
    "L3 = np.array([1,2,1]) / 4\n",
    "E3 = np.array([-1,0,1])\n",
    "S3 = np.array([-1,2,-1])\n",
    "llist = [L3 , E3 , S3]\n",
    "\n",
    "laws = []\n",
    "for xs in llist:\n",
    "    for ys in llist:\n",
    "        xs= np.reshape(xs,(3,1))\n",
    "        ys = np.reshape(ys,(1,3))\n",
    "        L3L3 = np.matmul(xs,ys)\n",
    "        laws.append(L3L3)\n",
    "\n",
    "ppp=[]\n",
    "fff= []\n",
    "for i in range(9):\n",
    "    f1 = cv2.filter2D(src=c, ddepth=-1, kernel= laws[i])\n",
    "    ppp.append(am_power(f1))\n",
    "    fff.append(f1)\n",
    "\n",
    "print('original image power c= ' , am_power(c) )\n",
    "for i in range(9):\n",
    "    print('power of c', i ,'th filter response=', ppp[i] )\n",
    "\n",
    "\n",
    "ppp=[]\n",
    "fff= []\n",
    "for i in range(9):\n",
    "    f1 = cv2.filter2D(src=d, ddepth=-1, kernel= laws[i])\n",
    "    ppp.append(am_power(f1))\n",
    "    fff.append(f1)\n",
    "\n",
    "print('original image power d= ' , am_power(d) )\n",
    "for i in range(9):\n",
    "    print('power of d', i ,'th filter response=', ppp[i] )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: bad Huffman code\n"
     ]
    }
   ],
   "source": [
    "x = cv2.imread('/Users/tianze/cs4243_lab/CS4243_2023_images_small/34.jpg', 0)\n",
    "y = cv2.imread('/Users/tianze/cs4243_lab/CS4243_2023_images_small/68.JPG', 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "hlp = np.full((3,3), 1/9)\n",
    "hhp = np.array([[-1,-1,-1],[-1,8,-1],[-1,-1,-1]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "power of x low pass filter response= 20040.985943554722 \n",
      "power of x high pass filter response= 218.39124206679634 \n",
      "power of y low pass filter response= 14851.285573111156 \n",
      "power of y high pass filter response= 353.16680350349924\n"
     ]
    }
   ],
   "source": [
    "px = am_power(x)\n",
    "py = am_power(y)\n",
    "pxlp = am_power(cv2.filter2D(src=x, ddepth=-1, kernel=hlp))\n",
    "pxhp = am_power(cv2.filter2D(src=x, ddepth=-1, kernel=hhp))\n",
    "pylp = am_power(cv2.filter2D(src=y, ddepth=-1, kernel=hlp))\n",
    "pyhp = am_power(cv2.filter2D(src=y, ddepth=-1, kernel=hhp))\n",
    "\n",
    "print('power of x low pass filter response=', pxlp, '\\npower of x high pass filter response=', pxhp, '\\npower of y low pass filter response=', pylp, '\\npower of y high pass filter response=', pyhp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "xd = cv2.resize(x, None, fx=0.25, fy=0.25, interpolation=cv2.INTER_LINEAR)\n",
    "yd = cv2.resize(y, None, fx=0.25, fy=0.25, interpolation=cv2.INTER_LINEAR)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "power of x low pass filter response= 20043.852923584127 \n",
      "power of x high pass filter response= 750.31918285647 \n",
      "power of y low pass filter response= 14803.2328976782 \n",
      "power of y high pass filter response= 2755.5220748869583\n"
     ]
    }
   ],
   "source": [
    "pxd = am_power(xd)\n",
    "pyd = am_power(yd)\n",
    "pxdlp = am_power(cv2.filter2D(src=xd, ddepth=-1, kernel=hlp))\n",
    "pxdhp = am_power(cv2.filter2D(src=xd, ddepth=-1, kernel=hhp))\n",
    "pydlp = am_power(cv2.filter2D(src=yd, ddepth=-1, kernel=hlp))\n",
    "pydhp = am_power(cv2.filter2D(src=yd, ddepth=-1, kernel=hhp))\n",
    "\n",
    "print('power of x low pass filter response=', pxdlp, '\\npower of x high pass filter response=', pxdhp, '\\npower of y low pass filter response=', pydlp, '\\npower of y high pass filter response=', pydhp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010889743074898523 0.9973959212582383 0.023718292103678706 0.9973959212582383\n",
      "0.03735868893323736 0.9979913662143187 0.18405719818066615 0.988793229418889\n"
     ]
    }
   ],
   "source": [
    "print(pxhp/px, pylp/py, pyhp/py, pylp/py)\n",
    "print(pxdhp/pxd, pxdlp/pxd, pydhp/pyd, pydlp/pyd)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q4\n",
    "Specify how optical flow can be used to determine:\n",
    "a. mutual velocity of an observer and an object.\n",
    "b. The focus of expansion.\n",
    "c. Distance of a moving object from the observer.\n",
    "d. Possible collision of the object with an observer and time of collision.\n",
    "\n",
    "Ans:\n",
    "a. Mutual Velocity of an Observer and an Object:\n",
    "Optical flow computes the displacement of pixels between two consecutive frames. This displacement can be used to estimate the relative velocity between the observer (camera) and an object.\n",
    "The velocity vector of a point (or region) in the scene can be estimated by computing the magnitude and direction of its optical flow.\n",
    "If the observer is stationary, the computed optical flow directly corresponds to the motion of the object. If both the observer and object are moving, the computed optical flow is a combination of both motions, and additional information or assumptions may be needed to separate them.\n",
    "\n",
    "b. The Focus of Expansion:\n",
    "When an observer is moving through a scene, the point in the image towards which the observer is moving is called the focus of expansion (FOE). All the optical flow vectors radiate out from this point.\n",
    "By analyzing the direction of the optical flow vectors across the image, one can determine the FOE as the point where these vectors converge or originate. For instance, when driving forward on a straight road, the FOE would be somewhere in the middle of the horizon, and all the scene elements would seem to move away from that point.\n",
    "\n",
    "c. Distance of a Moving Object from the Observer:\n",
    "The magnitude of optical flow is inversely proportional to the distance of the object from the observer. Objects closer to the camera will have a larger optical flow than distant ones, given the same actual velocity.\n",
    "To precisely determine the distance, calibration is needed. Once calibrated, one can use the disparity between the observed optical flow and the expected optical flow (based on object's known speed) to estimate distance.\n",
    "It's important to note that this method is more qualitative than quantitative. For more precise measurements, methods like stereo vision or depth sensing are typically used in combination with optical flow.\n",
    "\n",
    "d. Possible Collision of the Object with an Observer and Time of Collision:\n",
    "If an object is on a collision course with the observer, its trajectory will lead it to the FOE. Thus, monitoring the optical flow vectors can help determine if they are converging towards the FOE.\n",
    "The time to collision (TTC) can be estimated by the inverse of the rate of expansion of the optical flow from the FOE. Specifically, TTC can be approximated as the ratio of the distance of the object to its relative speed. If d is the distance of the object from the observer and v is its relative speed towards the observer (computed from optical flow), then TTC = d/v.\n",
    "For more accurate calculations, it's often useful to track the object over several frames to refine the optical flow estimates and thereby refine TTC calculations.\n",
    "While optical flow provides valuable insights into scene dynamics, it's essential to note that it can be affected by factors like lighting changes, occlusions, and noise. Thus, in real-world applications, it's often combined with other methods or sensors for improved robustness and accuracy.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "fr11 = cv2.imread('/Users/tianze/cs4243_lab/Python_notebooks/set5/OF_samples/fr1.png', 0)\n",
    "fr12 = cv2.imread('/Users/tianze/cs4243_lab/Python_notebooks/set5/OF_samples/fr2.png', 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}