{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b0ca6cb",
   "metadata": {},
   "source": [
    "# Lab Weeks 6\n",
    "\n",
    "Author: Dr. Amirhassan MONAJEMI. Modified by Xiao CAO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e234ce6",
   "metadata": {},
   "source": [
    "\n",
    "### part 1:  \n",
    "#### CW1\n",
    "Question1:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60162d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a random grayscale image of size 400x400\n",
    "# np.random.seed(0)\n",
    "# original_image = np.random.randint(0, 256, (400, 400), dtype=np.uint8)\n",
    "#In case you don't have the image\n",
    "\n",
    "image_path='/Users/cx/Documents/GitHub/cs4243_lab/images/20220511_105950gl.jpg'\n",
    "original_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "# Initialize an empty dictionary to store the absolute difference values\n",
    "adiff_values = {}\n",
    "\n",
    "# Loop through all interpolation algorithms\n",
    "for x, algo in zip([0, 1, 2, 3], [cv2.INTER_NEAREST,cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA]):\n",
    "    # Zoom out by a factor of 0.25\n",
    "    print(x,algo)\n",
    "    zoomed_out_image = cv2.resize(original_image, None, fx=0.25, fy=0.25, interpolation=algo)\n",
    "    \n",
    "    # Zoom in by a factor of 4\n",
    "    zoomed_in_image = cv2.resize(zoomed_out_image, (original_image.shape[1], original_image.shape[0]), interpolation=algo)\n",
    "    \n",
    "    # Calculate the absolute difference\n",
    "    adiff = np.sum(np.abs(original_image.astype(\"float32\") - zoomed_in_image.astype(\"float32\")))\n",
    "    \n",
    "    # Store the value in the dictionary\n",
    "    adiff_values[algo] = adiff\n",
    "\n",
    "# Sort the adiff_values by value\n",
    "sorted_adiff = sorted(adiff_values.items(), key=lambda x: x[1])\n",
    "\n",
    "# Display the sorted adiff values\n",
    "sorted_adiff\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1ee902",
   "metadata": {},
   "source": [
    "Question2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7200f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def calculate_power(image):\n",
    "    return np.sum(image.astype('float') ** 2) / (image.shape[0] * image.shape[1])\n",
    "\n",
    "def calculate_entropy(image):\n",
    "    hist = cv2.calcHist([image], [0], None, [256], [0, 256])\n",
    "    #cv2.calcHist(images, channels, mask, histSize, ranges)\n",
    "    hist = hist.ravel() / hist.sum()\n",
    "    #hist.ravel(): lattens the histogram array using ravel() to make it a one-dimensional array.\n",
    "    entropy = -np.sum(hist * np.log2(hist + np.finfo(float).eps))\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e5fcff",
   "metadata": {},
   "source": [
    "Here, the entropy is calculated using the formula:\n",
    "\n",
    "$$\n",
    "\\text{Entropy} = -\\sum_{i} p(i) \\log_{2}{p(i)}\n",
    "$$\n",
    "\n",
    "Where $$ p(i) $$ is the probability of occurrence of intensity value \\( i \\), which is what we have in the normalized histogram. The term `np.finfo(float).eps` is a very small constant added to avoid the logarithm of zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a92f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_path_b='/Users/cx/Documents/GitHub/cs4243_lab/images/20230513_190534gl.jpg'\n",
    "image_path_c='/Users/cx/Documents/GitHub/cs4243_lab/images/20230324_105524gl.jpg'\n",
    "image_b = cv2.imread(image_path_b, cv2.IMREAD_GRAYSCALE)\n",
    "image_c = cv2.imread(image_path_c, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Apply 5x5 Gaussian filter to b and c to get bGLP and cGLP\n",
    "image_bGLP = cv2.GaussianBlur(image_b, (5, 5), 0)\n",
    "image_cGLP = cv2.GaussianBlur(image_c, (5, 5), 0)\n",
    "\n",
    "# Calculate power and entropy for b and bGLP\n",
    "power_b = calculate_power(image_b)\n",
    "power_bGLP = calculate_power(image_bGLP)\n",
    "entropy_b = calculate_entropy(image_b)\n",
    "entropy_bGLP = calculate_entropy(image_bGLP)\n",
    "\n",
    "# Calculate power and entropy for c and cGLP\n",
    "power_c = calculate_power(image_c)\n",
    "power_cGLP = calculate_power(image_cGLP)\n",
    "entropy_c = calculate_entropy(image_c)\n",
    "entropy_cGLP = calculate_entropy(image_cGLP)\n",
    "\n",
    "# Calculate percentage of power and entropy change for b\n",
    "power_change_b = ((power_b - power_bGLP) / power_b) * 100\n",
    "entropy_change_b = ((entropy_b - entropy_bGLP) / entropy_b) * 100\n",
    "\n",
    "# Calculate percentage of power and entropy change for c\n",
    "power_change_c = ((power_c - power_cGLP) / power_c) * 100\n",
    "entropy_change_c = ((entropy_c - entropy_cGLP) / entropy_c) * 100\n",
    "\n",
    "print('Image B: Power change: {:.2f}%, Entropy change: {:.2f}%'.format(power_change_b, entropy_change_b))\n",
    "print('Image C: Power change: {:.2f}%, Entropy change: {:.2f}%'.format(power_change_c, entropy_change_c))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d6633f",
   "metadata": {},
   "source": [
    "Given these results, it appears that for image b, the Gaussian filter cuts a significantly higher percentage of power compared to image c. On the other hand, the change in entropy for both images b and c is not significantly different.\n",
    "Therefore, the option that best represents these observations would be:\n",
    "\n",
    "a. For \n",
    "b, the filter relatively cuts more percentage of power compared to c, because b has got more high-frequency components/details compared to c. The change in entropy, however, is not significantly different for b and c."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101dba09",
   "metadata": {},
   "source": [
    "### Question3:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23510720",
   "metadata": {},
   "source": [
    "#### Butterworth Bandpass Filter Formulation\n",
    "\n",
    "#### Objective\n",
    "\n",
    "The objective is to create a Butterworth bandpass filter that allows frequencies within a specified range to pass through while attenuating the frequencies outside this range.\n",
    "\n",
    "#### Parameters\n",
    "\n",
    "- \\( d_0 \\) : Lower cut-off frequency\n",
    "- \\( d_1 \\) : Upper cut-off frequency\n",
    "- \\( n \\) : Order of the filter\n",
    "\n",
    "#### Formulation\n",
    "\n",
    "1. **Frequency Coordinates**: Create frequency coordinates \\( u \\) and \\( v \\) for the filter.\n",
    "   \n",
    "2. **Radius Calculation**: Calculate the distance \\( D(u, v) \\) from the origin in the frequency domain to each point \\( (u, v) \\).\n",
    "\n",
    "$$\n",
    "D(u, v) = \\sqrt{u^2 + v^2}\n",
    "$$\n",
    "\n",
    "3. **Butterworth Low-Pass Filter**: First, create a Butterworth low-pass filter $$ H_{LP}(u,v) $$ using the formula:\n",
    "\n",
    "$$\n",
    "H_{LP}(u,v) = \\frac{1}{1 + \\left( \\frac{D(u,v)}{d_0} \\right)^{2n}}\n",
    "$$\n",
    "\n",
    "4. **Convert to High-Pass Filter**: Subtract the low-pass filter from 1.\n",
    "\n",
    "$$\n",
    "H_{HP}(u,v) = 1 - H_{LP}(u,v)\n",
    "$$\n",
    "\n",
    "5. **Apply Upper Cut-off**: Set the filter values to zero where \\( D(u, v) > d_1 \\).\n",
    "\n",
    "$$\n",
    "H_{HP}(u,v) = 0 \\quad \\text{if} \\quad D(u, v) > d_1\n",
    "$$\n",
    "\n",
    "6. **Butterworth Bandpass Filter**: The final Butterworth bandpass filter \\( H(u, v) \\) is:\n",
    "\n",
    "$$\n",
    "H(u, v) = H_{HP}(u,v) \\quad \\text{if} \\quad D(u, v) \\leq d_1\n",
    "$$\n",
    "\n",
    "#### Conclusion\n",
    "\n",
    "The Butterworth bandpass filter is used to allow frequencies within a certain range \\( [d_0, d_1] \\) to pass through, which is useful for tasks like noise reduction, texture analysis, and various other applications in computer vision and signal processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b320736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing additional library for Fourier Transform and Butterworth Filter\n",
    "from scipy.fftpack import fftshift, fft2, ifft2, ifftshift\n",
    "\n",
    "# Read the uploaded grayscale image 'c'\n",
    "image_path_c = '/Users/cx/Documents/GitHub/cs4243_lab/images/IMG_0699_1024.png'\n",
    "image_c = cv2.imread(image_path_c, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Function to create a Butterworth Bandpass Filter\n",
    "def ButterworthBandPass(rows, cols, d0, d1, n):\n",
    "    u = np.fft.fftfreq(rows)\n",
    "    v = np.fft.fftfreq(cols)\n",
    "    radius = np.sqrt((u[:, None])**2 + (v[None, :])**2)\n",
    "    filter_ = 1 / (1 + (radius / d0)**(2*n))\n",
    "    filter_ = 1 - filter_\n",
    "    filter_[radius > d1] = 0\n",
    "    return fftshift(filter_)\n",
    "\n",
    "# Compute the Fourier transform of the image\n",
    "f_transform_c = fft2(image_c)\n",
    "f_transform_c = fftshift(f_transform_c)\n",
    "\n",
    "# Initialize an empty dictionary to store the power values\n",
    "power_values = {}\n",
    "\n",
    "# Create Butterworth Bandpass Filters and apply them\n",
    "for i, (d0, d1) in enumerate([(0.05, 0.1), (0.1, 0.2), (0.2, 0.4), (0.4, 0.8)]):\n",
    "    # Create Butterworth filter\n",
    "    butterworth_filter = ButterworthBandPass(1024, 1024, d0, d1, 1)\n",
    "    \n",
    "    # Apply the filter\n",
    "    filtered_f_transform = f_transform_c * butterworth_filter\n",
    "    \n",
    "    # Perform inverse Fourier transform\n",
    "    filtered_image = ifft2(ifftshift(filtered_f_transform))\n",
    "    \n",
    "    # Calculate the power of the resulting image\n",
    "    power_values[f'PcF{i}'] = calculate_power(np.abs(filtered_image))\n",
    "\n",
    "# Sort the power_values by value\n",
    "sorted_power = sorted(power_values.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "sorted_power\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d3537c",
   "metadata": {},
   "source": [
    "\n",
    "#### Results\n",
    "\n",
    "The calculated powers \\( PcFi \\) for each resulting image \\( FcFi \\) are as follows:\n",
    "\n",
    "- \\( PcF0 = 42.98 \\)\n",
    "- \\( PcF1 = 38.23 \\)\n",
    "- \\( PcF2 = 28.55 \\)\n",
    "- \\( PcF3 = 10.09 \\)\n",
    "\n",
    "#### Conclusion\n",
    "\n",
    "Based on these calculations, the power of the filtered images decreases as we go from \\( F0 \\) to \\( F3 \\). This leads us to select the following option:\n",
    "\n",
    "d. \\( PcF0 > PcF1 > PcF2 > PcF3 \\), the last filter parameter is not significant. The setting of the lower and higher cut-off frequencies is designed to cover all the spatial frequency components.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371e321c",
   "metadata": {},
   "source": [
    "### Question4:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d155f8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate power of an image\n",
    "def calculate_power(image):\n",
    "    return np.sum(image.astype(\"float32\") ** 2)/ (image.shape[0] * image.shape[1])\n",
    "\n",
    "# Re-read the uploaded grayscale image 'a'\n",
    "image_path_a = '/Users/cx/Documents/GitHub/cs4243_lab/images/IMG_20200111_141756.jpg'\n",
    "image_a = cv2.imread(image_path_a, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Initialize an empty dictionary to store the power values for image 'a'\n",
    "power_values_a = {}\n",
    "\n",
    "# Function to apply Gaussian filter\n",
    "def apply_gaussian_filter(image, size=(5, 5), sigma=1):\n",
    "    return cv2.GaussianBlur(image, size, sigma)\n",
    "\n",
    "# Function to apply Vertical Edge Detector filter\n",
    "def apply_ved_filter(image):\n",
    "    ved_filter = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "    return cv2.filter2D(image, -1, ved_filter)\n",
    "\n",
    "# Calculate the power of the original image 'a'\n",
    "power_values_a['Pa'] = calculate_power(image_a)\n",
    "\n",
    "# Apply Vertical Edge Detector filter to image 'a' and calculate its power\n",
    "filtered_a_ved = apply_ved_filter(image_a)\n",
    "power_values_a['Phpa'] = calculate_power(filtered_a_ved)\n",
    "\n",
    "# Apply Gaussian filter to image 'a', then apply Vertical Edge Detector filter and calculate its power\n",
    "filtered_a_gaussian = apply_gaussian_filter(image_a)\n",
    "filtered_a_gaussian_ved = apply_ved_filter(filtered_a_gaussian)\n",
    "power_values_a['Plphpa'] = calculate_power(filtered_a_gaussian_ved)\n",
    "\n",
    "# Apply Gaussian filter twice to image 'a', then apply Vertical Edge Detector filter and calculate its power\n",
    "filtered_a_gaussian_twice = apply_gaussian_filter(filtered_a_gaussian)\n",
    "filtered_a_gaussian_twice_ved = apply_ved_filter(filtered_a_gaussian_twice)\n",
    "power_values_a['Plplphpa'] = calculate_power(filtered_a_gaussian_twice_ved)\n",
    "\n",
    "power_values_a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c364e8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(power_values_a['Plplphpa']/power_values_a['Phpa'])\n",
    "print(power_values_a['Plplphpa']/power_values_a['Pa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0878abb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the uploaded grayscale image 'b'\n",
    "image_path_b = '/Users/cx/Documents/GitHub/cs4243_lab/images/high_spat_freq.bmp'\n",
    "image_b = cv2.imread(image_path_b, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Initialize an empty dictionary to store the power values for image 'b'\n",
    "power_values_b = {}\n",
    "\n",
    "# Calculate the power of the original image 'b'\n",
    "power_values_b['Pb'] = calculate_power(image_b)\n",
    "\n",
    "# Apply Vertical Edge Detector filter to image 'b' and calculate its power\n",
    "filtered_b_ved = apply_ved_filter(image_b)\n",
    "power_values_b['Phpb'] = calculate_power(filtered_b_ved)\n",
    "\n",
    "# Apply Gaussian filter to image 'b', then apply Vertical Edge Detector filter and calculate its power\n",
    "filtered_b_gaussian = apply_gaussian_filter(image_b)\n",
    "filtered_b_gaussian_ved = apply_ved_filter(filtered_b_gaussian)\n",
    "power_values_b['Plphpb'] = calculate_power(filtered_b_gaussian_ved)\n",
    "\n",
    "# Apply Gaussian filter twice to image 'b', then apply Vertical Edge Detector filter and calculate its power\n",
    "filtered_b_gaussian_twice = apply_gaussian_filter(filtered_b_gaussian)\n",
    "filtered_b_gaussian_twice_ved = apply_ved_filter(filtered_b_gaussian_twice)\n",
    "power_values_b['Plplphpb'] = calculate_power(filtered_b_gaussian_twice_ved)\n",
    "\n",
    "power_values_b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac1c9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(power_values_b['Plplphpb']/power_values_b['Phpb'])\n",
    "print(power_values_b['Plplphpb']/power_values_b['Pb'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddb7662",
   "metadata": {},
   "source": [
    "----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72148ae",
   "metadata": {},
   "source": [
    "### Part 2: Texture Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4e3184",
   "metadata": {},
   "source": [
    "### LBP: Local Binary Patterns\n",
    "\n",
    "1. Develop a radial P=16, R=3 LBP function\n",
    "2. Try it on \n",
    "a. diag_texture.bmp \n",
    "b. hor_texture.jpg \n",
    "3. If the image is color, convert it to graylevel\n",
    "4. Draw the histogram of the LBP, see the differences\n",
    "5. In particular, compare the histogram of the LBPs of a and b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed08a95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as m\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "from matplotlib import pyplot as plt\n",
    "img = cv2.imread('/Users/cx/Documents/GitHub/cs4243_lab/images/diag_texture.bmp',0)\n",
    "img2=cv2.imread('/Users/cx/Documents/GitHub/cs4243_lab/images/hor_texture.jpg',0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c76c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbpmask163(a,x,y):\n",
    "    k = np.array( [ [ 0, 0 , 2**15 , 1 , 2 , 0 , 0 ] , \n",
    "                    [ 0 , 2**14 , 0 , 0 , 0 , 4 , 0] , \n",
    "                    [ 2**13 , 0, 0, 0, 0, 0, 8] , \n",
    "                    [ 2**12 , 0, 0, 0, 0, 0, 16] , \n",
    "                    [ 2**11 , 0 ,0 , 0, 0, 0, 32] , \n",
    "                    [ 0 , 2**10 , 0 , 0 , 0 , 64, 0] , \n",
    "                    [ 0, 0, 2**9 , 256, 128, 0, 0] ])\n",
    "\n",
    "    msk1 = np.zeros([7,7])\n",
    "    for i in range(7): \n",
    "        for j in range(7):\n",
    "            #Your Code Here\n",
    "            \n",
    "    \n",
    "    ans = np.sum( np.matmul( msk1 , k) )\n",
    " \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fe7272",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "for i in tqdm(range(3,M[0]-3)):\n",
    "    for j in range(3,M[1]-3):\n",
    "        #lbpres stand for lbp result\n",
    "        lbpres[i,j] = lbpmask163(img,i,j)\n",
    "lbpres = lbpres[ 3:M[0]-3 , 3:M[1]-3 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b6a9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist,bins = np.histogram(img.flatten(),256,[0,256])\n",
    "\n",
    "cdf = hist.cumsum()\n",
    "cdf_normalized = cdf * hist.max()/ cdf.max()\n",
    "\n",
    "plt.plot(cdf_normalized, color = 'g')\n",
    "plt.hist(img.flatten(),256,[0,256], color = 'r')\n",
    "plt.xlim([0,256])\n",
    "plt.legend(('cdf','orig hist'), loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f3b1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LBP histogram \n",
    "#\n",
    "hist,bins = np.histogram(lbpres.flatten(),2**16,[0,2**16])\n",
    "\n",
    "cdf = hist.cumsum()\n",
    "cdf_normalized = cdf * hist.max()/ cdf.max()\n",
    "\n",
    "plt.plot(cdf_normalized, color = 'g')\n",
    "plt.hist(lbpres.flatten(),2**16,[0,2**16], color = 'r')\n",
    "plt.xlim([0,2**16])\n",
    "plt.legend(('cdf','LBP hist'), loc = 'upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
